{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757ff3c0",
   "metadata": {
    "id": "757ff3c0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import model, utils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf7e525",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaf7e525",
    "outputId": "54ff273e-bda8-4ebf-b274-29dc5652036c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "device = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63422cae",
   "metadata": {
    "id": "63422cae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c016a2b8203c4055b995f13ded83c1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      6\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m      7\u001b[0m ])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the CIFAR-10 dataset\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m cifar10_train \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m pixel_means \u001b[38;5;241m=\u001b[39m cifar10_train\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m     12\u001b[0m pixel_stds \u001b[38;5;241m=\u001b[39m cifar10_train\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mstd(axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset not found or corrupted.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     69\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m You can use download=True to download it\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/cifar.py:143\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py:413\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    411\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 413\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(archive, extract_root))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py:139\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[0;32m--> 139\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mIOError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py:33\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: response\u001b[38;5;241m.\u001b[39mread(chunk_size), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m     35\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py:33\u001b[0m, in \u001b[0;36m_urlretrieve.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m     35\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## To get the std and mean value\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "cifar10_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "pixel_means = cifar10_train.data.mean(axis=(0,1,2)) / 255.0\n",
    "pixel_stds = cifar10_train.data.std(axis=(0,1,2)) / 255.0\n",
    "\n",
    "print('CIFAR-10 pixel means:', pixel_means)\n",
    "print('CIFAR-10 pixel stds:', pixel_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1112e2cf",
   "metadata": {
    "id": "1112e2cf"
   },
   "outputs": [],
   "source": [
    "# Train Phase transformations\n",
    "train_transforms = transforms.Compose([\n",
    "                                      #  transforms.Resize((28, 28)),\n",
    "                                       #transforms.ColorJitter(brightness=0.40, contrast=0.4, saturation=0.40, hue=0.4),\n",
    "                                       #transforms.RandomRotation((-7.0, 7.0), fill=(1,1,1)),\n",
    "                                       #transforms.Resize((32, 32)),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(pixel_means, pixel_stds),\n",
    "                                       #transforms.RandomHorizontalFlip(p = 0.5),\n",
    "                                       #transforms.RandomCrop(28, padding=4),\n",
    "                                       #transforms.RandomErasing(p=0.5, scale=(0.2, 0.4), ratio=(0.3, 3.3))\n",
    "                                       ])\n",
    "\n",
    "# Test Phase transformations\n",
    "test_transforms = transforms.Compose([\n",
    "                                      #  transforms.Resize((28, 28)),\n",
    "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(pixel_means, pixel_stds)\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76ba0341",
   "metadata": {
    "id": "76ba0341"
   },
   "outputs": [],
   "source": [
    "train = datasets.CIFAR10('./data', train=True, download=True, transform=train_transforms)\n",
    "test = datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)\n",
    "\n",
    "print(train.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e4bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visulizing the data set \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Get a batch of images from the dataloader\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Plot the images using Matplotlib\n",
    "fig, axs = plt.subplots(4, 4, figsize=(12, 6))\n",
    "for i in range(16):\n",
    "    # Calculate the subplot index\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    # Unnormalize the image\n",
    "    img = images[i] / 2 + 0.5\n",
    "    # Convert the image to a NumPy array\n",
    "    npimg = img.numpy()\n",
    "    # Transpose the image from (C, H, W) to (H, W, C)\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    # Plot the image\n",
    "    axs[row, col].imshow(npimg)\n",
    "    axs[row, col].set_title(classes[labels[i]])\n",
    "    axs[row, col].axis('off')\n",
    "\n",
    "fig.subplots_adjust(hspace=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc97812f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc97812f",
    "outputId": "1547de60-2962-4143-c5b1-b861fd4d1b17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "\n",
    "# CUDA?\n",
    "cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", cuda)\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# dataloader arguments - something you'll fetch these from cmdprmt\n",
    "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2a9a52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba2a9a52",
    "outputId": "c8a3932e-47f2-4b3f-e23e-ffb07064b8d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 26, 26]              90\n",
      "              ReLU-2           [-1, 10, 26, 26]               0\n",
      "       BatchNorm2d-3           [-1, 10, 26, 26]              20\n",
      "           Dropout-4           [-1, 10, 26, 26]               0\n",
      "            Conv2d-5           [-1, 16, 24, 24]           1,440\n",
      "              ReLU-6           [-1, 16, 24, 24]               0\n",
      "       BatchNorm2d-7           [-1, 16, 24, 24]              32\n",
      "           Dropout-8           [-1, 16, 24, 24]               0\n",
      "            Conv2d-9           [-1, 10, 24, 24]             160\n",
      "        MaxPool2d-10           [-1, 10, 12, 12]               0\n",
      "           Conv2d-11           [-1, 10, 10, 10]             900\n",
      "             ReLU-12           [-1, 10, 10, 10]               0\n",
      "      BatchNorm2d-13           [-1, 10, 10, 10]              20\n",
      "          Dropout-14           [-1, 10, 10, 10]               0\n",
      "           Conv2d-15             [-1, 10, 8, 8]             900\n",
      "             ReLU-16             [-1, 10, 8, 8]               0\n",
      "      BatchNorm2d-17             [-1, 10, 8, 8]              20\n",
      "          Dropout-18             [-1, 10, 8, 8]               0\n",
      "           Conv2d-19             [-1, 13, 6, 6]           1,170\n",
      "             ReLU-20             [-1, 13, 6, 6]               0\n",
      "      BatchNorm2d-21             [-1, 13, 6, 6]              26\n",
      "          Dropout-22             [-1, 13, 6, 6]               0\n",
      "           Conv2d-23             [-1, 16, 4, 4]           1,872\n",
      "             ReLU-24             [-1, 16, 4, 4]               0\n",
      "      BatchNorm2d-25             [-1, 16, 4, 4]              32\n",
      "          Dropout-26             [-1, 16, 4, 4]               0\n",
      "        AvgPool2d-27             [-1, 16, 1, 1]               0\n",
      "           Conv2d-28             [-1, 10, 1, 1]             160\n",
      "================================================================\n",
      "Total params: 6,842\n",
      "Trainable params: 6,842\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.61\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "cnnmodel = model.Net().to(device)\n",
    "summary(cnnmodel, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8932ae7",
   "metadata": {
    "id": "d8932ae7"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = optim.Adam(cnnmodel.parameters(), lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "EPOCHS = 20\n",
    "criterion = F.nll_loss\n",
    "misclassified = []\n",
    "actual_labels = []\n",
    "predicted_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebeeb9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ebeeb9b",
    "outputId": "29a58865-8cd4-4cbf-bc6b-053c21839ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.20072446763515472 Batch_id=937 Accuracy=94.28: 100%|██████████| 938/938 [00:33<00:00, 28.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0449, Accuracy: 9861/10000 (98.61%)\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.18403847515583038 Batch_id=937 Accuracy=97.49: 100%|██████████| 938/938 [00:28<00:00, 32.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0595, Accuracy: 9795/10000 (97.95%)\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.02033323235809803 Batch_id=937 Accuracy=97.77: 100%|██████████| 938/938 [00:27<00:00, 34.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0368, Accuracy: 9880/10000 (98.80%)\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.005172247067093849 Batch_id=937 Accuracy=98.02: 100%|██████████| 938/938 [00:26<00:00, 34.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: reducing learning rate of group 0 to 1.0000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0328, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.030238453298807144 Batch_id=937 Accuracy=98.66: 100%|██████████| 938/938 [00:27<00:00, 33.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 9932/10000 (99.32%)\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.01155499741435051 Batch_id=937 Accuracy=98.74: 100%|██████████| 938/938 [00:29<00:00, 32.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 9938/10000 (99.38%)\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.023054830729961395 Batch_id=937 Accuracy=98.81: 100%|██████████| 938/938 [00:27<00:00, 34.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 9941/10000 (99.41%)\n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.006292472593486309 Batch_id=937 Accuracy=98.79: 100%|██████████| 938/938 [00:27<00:00, 34.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 9938/10000 (99.38%)\n",
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.06294827163219452 Batch_id=937 Accuracy=98.88: 100%|██████████| 938/938 [00:27<00:00, 34.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 9941/10000 (99.41%)\n",
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.00594619894400239 Batch_id=937 Accuracy=98.89: 100%|██████████| 938/938 [00:27<00:00, 34.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 9942/10000 (99.42%)\n",
      "\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0061103226616978645 Batch_id=937 Accuracy=98.89: 100%|██████████| 938/938 [00:27<00:00, 33.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 9940/10000 (99.40%)\n",
      "\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.008456820622086525 Batch_id=937 Accuracy=98.87: 100%|██████████| 938/938 [00:27<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 9942/10000 (99.42%)\n",
      "\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.05015682056546211 Batch_id=937 Accuracy=98.84: 100%|██████████| 938/938 [00:27<00:00, 34.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 9935/10000 (99.35%)\n",
      "\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.009836319833993912 Batch_id=937 Accuracy=98.89: 100%|██████████| 938/938 [00:27<00:00, 34.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 9937/10000 (99.37%)\n",
      "\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss=0.0192447230219841 Batch_id=937 Accuracy=98.89: 100%|██████████| 938/938 [00:29<00:00, 32.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 9942/10000 (99.42%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "  print(f'Epoch {epoch}')\n",
    "  loss = model.train(cnnmodel, device, train_loader, criterion, optimizer, epoch)\n",
    "  scheduler.step(loss)\n",
    "  model.test(cnnmodel, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229ebaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the misclassified Images\n",
    "model.plot_misclassifeid_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "model.plot_loss_accuracy_graph()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
